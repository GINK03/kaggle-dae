{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data (595212, 57)\n",
      "1:\n",
      "Training a LogisticRegression using a training set size of 446409. . .\n",
      "Trained model in 23.1728 seconds\n",
      "Predict model in 0.0249 seconds\n",
      "Gini score set: 0.1758.\n",
      "2:\n",
      "Training a SGDClassifier using a training set size of 446409. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.8953 seconds\n",
      "Predict model in 0.0190 seconds\n",
      "Gini score set: 0.0000.\n",
      "3:\n",
      "Training a DecisionTreeClassifier using a training set size of 446409. . .\n",
      "Trained model in 10.1964 seconds\n",
      "Predict model in 0.0686 seconds\n",
      "Gini score set: 0.0130.\n",
      "Predict model in 0.1318 seconds\n",
      "Gini score set: 0.1787.\n",
      "Finished in 257.7403 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, precision_score\n",
    "from time import time\n",
    "\n",
    "start_init = time()\n",
    "path = '../input/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "\n",
    "def predict_labels_gini(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "\n",
    "    print(\"Predict model in {:.4f} seconds\".format(end - start))\n",
    "    gini = 2 * roc_auc_score(target.values, y_pred) - 1\n",
    "    print(\"Gini score set: {:.4f}.\".format(gini))\n",
    "    return gini\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    start = time()\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "    return predict_labels_gini(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "def training(clfs, features, target):\n",
    "    print('Training data {}'.format(features.shape))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "    bestScore = 0\n",
    "    bestModel = None\n",
    "    for i, clf in enumerate(clfs):\n",
    "        print(\"{}:\".format(i + 1))\n",
    "        score = train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "        if bestScore < score:\n",
    "            bestScore = score\n",
    "            bestModel = clf\n",
    "    return bestModel\n",
    "\n",
    "\n",
    "def tuning(clf, features, target):\n",
    "    params = {}\n",
    "\n",
    "    if clf.__class__.__name__ == \"LogisticRegression\":\n",
    "        params = {'class_weight': ['balanced'],\n",
    "                  'C': [0.0003, 0.003, 0.03, 0.3]\n",
    "                  }\n",
    "    if clf.__class__.__name__ == \"DecisionTreeClassifier\":\n",
    "        params = {'criterion': ['gini', 'entropy']}\n",
    "    if params == {}:\n",
    "        return clf\n",
    "    grid_search = GridSearchCV(clf, params, scoring=make_scorer(precision_score))\n",
    "    grid_search.fit(features, target)\n",
    "    predict_labels_gini(grid_search, features, target)\n",
    "    return grid_search\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "target = train['target']\n",
    "features = train.drop(['id', 'target'], axis=1)\n",
    "\n",
    "clfs = [\n",
    "    LogisticRegression(class_weight='balanced'),\n",
    "    SGDClassifier(),\n",
    "    DecisionTreeClassifier()\n",
    "]\n",
    "bestModel              = training(clfs, features, target)\n",
    "bestModelTunned = tuning(bestModel, features, target)\n",
    "\n",
    "# Create submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test['id']\n",
    "test_pred = pd.DataFrame(test, columns=train.drop(['id', 'target'], axis=1).columns)\n",
    "y_test_pred = bestModelTunned.predict_proba(test_pred)[:, 1]\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('benchmark.csv', float_format='%.6f', index=False)\n",
    "end_init = time()\n",
    "print(\"Finished in {:.4f} seconds\".format(end_init - start_init))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
